{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics.quantile import QuantileLoss\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer\n",
    "from pytorch_forecasting.data.encoders import EncoderNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "data = pd.read_csv('dataset/preliminaryData/bss_activity_meteorological_popular-hours.csv')\n",
    "\n",
    "max_prediction_length = 7*6\n",
    "max_encoder_length = 15*6\n",
    "num_workers=32\n",
    "\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "data = data[lambda x: x.time_idx < data[\"time_idx\"].max() - 30*4*6]\n",
    "\n",
    "data[\"station\"] = data[\"station\"].astype(str)\n",
    "data[\"month\"] = data[\"month\"].astype(str)\n",
    "data[\"weekday\"] = data[\"weekday\"].astype(str)\n",
    "data[\"is_weekend\"] = data[\"is_weekend\"].astype(str)\n",
    "data[\"time_of_day\"] = data[\"time_of_day\"].astype(str)\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx < training_cutoff],\n",
    "    group_ids=[\"station\"],\n",
    "    target=\"activity\",\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_unknown_reals=[\"activity\", 'temp', 'humidity', 'avg_activity_by_station', 'log_activity'],\n",
    "    static_categoricals=[\"station\"],\n",
    "    time_varying_known_categoricals=[\"weekday\", \"is_weekend\", \"time_of_day\", \"month\"],\n",
    "    time_varying_known_reals=[\"is_public_hours\"],\n",
    "    target_normalizer=EncoderNormalizer(transformation=\"softplus\"),\n",
    "    lags={\"activity\": [6, 6*7,6*365]},\n",
    "    add_relative_time_idx=True,\n",
    "    add_encoder_length=True,\n",
    "    add_target_scales=True,\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=num_workers)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=num_workers)\n",
    "\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tuning\n",
    "\n",
    "import pickle\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"study_tft\",\n",
    "    n_trials=50,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 256),\n",
    "    hidden_continuous_size_range=(8, 186),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.0001, 0.1),\n",
    "    dropout_range=(0.1, 0.5),\n",
    "    trainer_kwargs=dict(limit_train_batches=30, devices=1),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    log_dir=\"study_tft\",\n",
    "    use_learning_rate_finder=True,\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"study_tft.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model run\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=True, mode=\"min\")\n",
    "logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=45,\n",
    "    accelerator='auto',\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.023,\n",
    "    callbacks=[early_stop_callback],\n",
    "    logger=logger)\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.001,\n",
    "    hidden_size=51,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.11493,\n",
    "    lstm_layers=2,\n",
    "    hidden_continuous_size=31,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation and interpretability\n",
    "\n",
    "from pytorch_forecasting.metrics.point import MAE\n",
    "\n",
    "lags = list(training.lags.values())[0] \n",
    "\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "\n",
    "raw_predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "for idx in range(10):\n",
    "    fig = best_tft.plot_prediction(raw_predictions.x, raw_predictions.output, idx=idx, add_loss_to_title=True)\n",
    "    fig.savefig(f\"performance/tft/performance_{idx}.jpg\")\n",
    "\n",
    "predictions = best_tft.predict(val_dataloader, return_y=True)\n",
    "mean_losses = MAE(reduction=\"none\")(predictions.output, predictions.y).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)\n",
    "\n",
    "for idx in range(10): \n",
    "    fig = best_tft.plot_prediction(\n",
    "        raw_predictions.x,\n",
    "        raw_predictions.output,\n",
    "        idx=indices[idx],\n",
    "        add_loss_to_title=MAE(quantiles=best_tft.loss.quantiles),\n",
    "    )\n",
    "    fig.savefig(f\"performance/tft/worst_performance_{idx}.jpg\")\n",
    "\n",
    "interpretation = best_tft.interpret_output(raw_predictions.output, reduction=\"sum\")\n",
    "figs = best_tft.plot_interpretation(interpretation)\n",
    "for key, value in figs.items():\n",
    "    value.savefig(f\"performance/tft/importance_{key}.jpg\")\n",
    "\n",
    "predictions = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(predictions.x, predictions.output)\n",
    "all_features = list(set(predictions_vs_actuals['support'].keys())-set([\"activity_lagged_by_\" + str(x) for x in lags]))\n",
    "\n",
    "figs = []\n",
    "for feature in all_features:\n",
    "    figs.append(best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals, name=feature))\n",
    "\n",
    "for key, value in enumerate(figs):\n",
    "    value.savefig(f\"performance/tft/_p_vs_a_{key}.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
